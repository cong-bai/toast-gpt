program: train.py
method: grid
metric:
  name: train/loss
  goal: minimize
parameters:
  log_interval:
    value: 1
  dataset:
    values: ['shakespeare', 'bookcorpus']
  gradient_accumulation_steps:
    value: 8
  batch_size:
    value: 12
  block_size:
    value: 1024
  n_layer:
    value: 6
  n_head:
    value: 6
  n_embd:
    value: 192
  beta1:
    value: 0.9
  beta2:
    value: 0.85
  learning_rate:
    values: [1e-2, 1e-3, 3e-2, 3e-3]
  max_iters:
    value: 10000
  lr_decay_iters:
    value: 10000
  warmup_iters:
    value: 2000
  eval_iters:
    value: 20
  eval_interval:
    value: 20
  matrix_eps:
    values: [1e-9]
  weight_decay:
    values: [1e-1]
  gradient_value_clip:
    value: -1
  optim:
    values: ['Shampoo','AdamW']
  grafting:
    value: 'AdaGrad'
command:
  - ${env}
  - torchrun 
  - --standalone 
  - --nproc_per_node=4
  - ${program}
  - ${args_no_boolean_flags}